<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apache Kafka documentation</title>
    <link>http://localhost:8080/35/documentation/streams/</link>
    <description>Recent content on Apache Kafka documentation</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="http://localhost:8080/35/documentation/streams/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>http://localhost:8080/35/documentation/streams/architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:8080/35/documentation/streams/architecture/</guid>
      <description>Architecture # Kafka Streams simplifies application development by building on the Kafka producer and consumer libraries and leveraging the native capabilities of Kafka to offer data parallelism, distributed coordination, fault tolerance, and operational simplicity. In this section, we describe how Kafka Streams works underneath the covers.
The picture below shows the anatomy of an application that uses the Kafka Streams library. Let&#39;s walk through some details.
{.centered style=&amp;ldquo;width:750px&amp;rdquo;}
Stream Partitions and Tasks # The messaging layer of Kafka partitions data for storing and transporting it.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:8080/35/documentation/streams/core-concepts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:8080/35/documentation/streams/core-concepts/</guid>
      <description>Core Concepts # Kafka Streams is a client library for processing and analyzing data stored in Kafka. It builds upon important stream processing concepts such as properly distinguishing between event time and processing time, windowing support, and simple yet efficient management and real-time querying of application state.
Kafka Streams has a low barrier to entry: You can quickly write and run a small-scale proof-of-concept on a single machine; and you only need to run additional instances of your application on multiple machines to scale up to high-volume production workloads.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:8080/35/documentation/streams/quickstart/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:8080/35/documentation/streams/quickstart/</guid>
      <description>Run Kafka Streams Demo Application # This tutorial assumes you are starting fresh and have no existing Kafka or ZooKeeper data. However, if you have already started Kafka, feel free to skip the first two steps.
Kafka Streams is a client library for building mission-critical real-time applications and microservices, where the input and/or output data is stored in Kafka clusters. Kafka Streams combines the simplicity of writing and deploying standard Java and Scala applications on the client side with the benefits of Kafka&#39;s server-side cluster technology to make these applications highly scalable, elastic, fault-tolerant, distributed, and much more.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:8080/35/documentation/streams/to-be-removed/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:8080/35/documentation/streams/to-be-removed/</guid>
      <description>Kafka Streams Introduction Run Demo App Tutorial: Write App Concepts Architecture Developer Guide Upgrade The easiest way to write mission-critical real-time applications and microservices Kafka Streams is a client library for building applications and microservices, where the input and output data are stored in Kafka clusters. It combines the simplicity of writing and deploying standard Java and Scala applications on the client side with the benefits of Kafka&#39;s server-side cluster technology.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:8080/35/documentation/streams/tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:8080/35/documentation/streams/tutorial/</guid>
      <description>Tutorial: Write a Kafka Streams Application # In this guide we will start from scratch on setting up your own project to write a stream processing application using Kafka Streams. It is highly recommended to read the quickstart first on how to run a Streams application written in Kafka Streams if you have not done so.
Setting up a Maven Project # We are going to use a Kafka Streams Maven Archetype for creating a Streams project structure with the following commands:</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:8080/35/documentation/streams/upgrade-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:8080/35/documentation/streams/upgrade-guide/</guid>
      <description>Upgrade Guide and API Changes # Upgrading from any older version to {{fullDotVersion}} is possible: if upgrading from 3.2 or below, you will need to do two rolling bounces, where during the first rolling bounce phase you set the config upgrade.from=&amp;quot;older version&amp;quot; (possible values are &amp;quot;0.10.0&amp;quot; - &amp;quot;3.2&amp;quot;) and during the second you remove it. This is required to safely handle 2 changes. The first is introduction of the new cooperative rebalancing protocol of the embedded consumer.</description>
    </item>
    
  </channel>
</rss>
